{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b641de57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gokha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gokha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gokha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gokha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk #language processing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ba5e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"congressional_tweet_training_data.csv\",names=None)\n",
    "data_test= pd.read_csv(\"congressional_tweet_test_data.csv\",names=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ec7bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>KUSI</td>\n",
       "      <td>10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>111</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>MO03</td>\n",
       "      <td>2</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>TeamUSA WorldJuniors</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>ImmigrantHeritageMonth</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   favorite_count                                          full_text  \\\n",
       "0               0  b\"RT @KUSINews: One of our longtime viewers wa...   \n",
       "1             258  b\"Today I'm urging the @CDCgov to immediately ...   \n",
       "2               0  b'Tomorrow, #MO03 seniors graduate from Calvar...   \n",
       "3               9  b'Congrats to #TeamUSA and Canton Native @JGre...   \n",
       "4               3  b'Pleased to support @amergateways at their Ju...   \n",
       "\n",
       "                 hashtags  retweet_count    year party_id  \n",
       "0                    KUSI             10  2017.0        R  \n",
       "1             Coronavirus            111  2020.0        R  \n",
       "2                    MO03              2  2014.0        R  \n",
       "3    TeamUSA WorldJuniors              3  2017.0        R  \n",
       "4  ImmigrantHeritageMonth              3  2019.0        D  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5848d3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>b'#TaxReform improved the playing field for Am...</td>\n",
       "      <td>TaxReform</td>\n",
       "      <td>13</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>b'This #NativeWomensEqualPay Day, we recommit ...</td>\n",
       "      <td>NativeWomensEqualPay</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>b\"\\xe2\\x80\\x9cI became convinced that our gene...</td>\n",
       "      <td>MeToo ShatteringTheSilence</td>\n",
       "      <td>24</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>b'During #NationalAdoptionMonth, we honor the ...</td>\n",
       "      <td>NationalAdoptionMonth</td>\n",
       "      <td>2</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>b'Happy #AirborneDay to our @USArmy paratroope...</td>\n",
       "      <td>AirborneDay AirborneAllTheWay</td>\n",
       "      <td>7</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  favorite_count                                          full_text  \\\n",
       "0   0              70  b'#TaxReform improved the playing field for Am...   \n",
       "1   1              27  b'This #NativeWomensEqualPay Day, we recommit ...   \n",
       "2   2              49  b\"\\xe2\\x80\\x9cI became convinced that our gene...   \n",
       "3   3              14  b'During #NationalAdoptionMonth, we honor the ...   \n",
       "4   4              13  b'Happy #AirborneDay to our @USArmy paratroope...   \n",
       "\n",
       "                        hashtags  retweet_count    year party  \n",
       "0                      TaxReform             13  2018.0     D  \n",
       "1           NativeWomensEqualPay             11     NaN     D  \n",
       "2     MeToo ShatteringTheSilence             24  2017.0     D  \n",
       "3          NationalAdoptionMonth              2  2019.0     D  \n",
       "4  AirborneDay AirborneAllTheWay              7  2018.0     D  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eee3bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['party_class']=data_train['party_id'].apply(lambda x: 0 if x=='D' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4fcae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['party_class']=data_test['party'].apply(lambda x: 0 if x=='D' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40386683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party_id</th>\n",
       "      <th>party_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>KUSI</td>\n",
       "      <td>10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>111</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>MO03</td>\n",
       "      <td>2</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>TeamUSA WorldJuniors</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>ImmigrantHeritageMonth</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   favorite_count                                          full_text  \\\n",
       "0               0  b\"RT @KUSINews: One of our longtime viewers wa...   \n",
       "1             258  b\"Today I'm urging the @CDCgov to immediately ...   \n",
       "2               0  b'Tomorrow, #MO03 seniors graduate from Calvar...   \n",
       "3               9  b'Congrats to #TeamUSA and Canton Native @JGre...   \n",
       "4               3  b'Pleased to support @amergateways at their Ju...   \n",
       "\n",
       "                 hashtags  retweet_count    year party_id  party_class  \n",
       "0                    KUSI             10  2017.0        R            1  \n",
       "1             Coronavirus            111  2020.0        R            1  \n",
       "2                    MO03              2  2014.0        R            1  \n",
       "3    TeamUSA WorldJuniors              3  2017.0        R            1  \n",
       "4  ImmigrantHeritageMonth              3  2019.0        D            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start by cleaning the full text of the tweets \n",
    "data_train.dropna(subset=['full_text'],inplace=True) #First, I drop the rows with NA in the text column\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac0690fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=data_train.reset_index(drop=True) #to fix the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bb75ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train=data_train[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and tag full version\n",
    "#tagged_tokens=[pos_tag(word_tokenize(sent)) for sent in data_train['full_text']]\n",
    "\n",
    "\n",
    "# apply version\n",
    "# data_train['tokenized_text'] = data_train['full_text'].apply(word_tokenize) \n",
    "# data_train['tagged_tokens'] = data_train['tokenized_text'].apply(pos_tag)\n",
    "\n",
    "\n",
    "### seperate version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "835e41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "tokens_list=[word_tokenize(sent) for sent in data_train['full_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def46985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pos Tag \n",
    "tagged_tokens =[pos_tag(sent) for sent in tokens_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf212fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag): #Following from [16]\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None # for easy if-statement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ea80fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b043fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame(data_train['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2632dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['tagged_tokens']=tagged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6acf3b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_list = x['tagged_tokens'].transform(lambda value: ' '.join([lemmatizer.lemmatize(a[0],pos=get_wordnet_pos(a[1])) if get_wordnet_pos(a[1]) else a[0] for a in  value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "592cacb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['lemma_list']=lemma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf04f537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>tagged_tokens</th>\n",
       "      <th>lemma_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>[(b, NN), ('', ''), (RT, NNP), (@, NNP), (KUSI...</td>\n",
       "      <td>b '' RT @ KUSINews : One of our longtime viewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>[(b, NN), ('', ''), (Today, NN), (I, PRP), ('m...</td>\n",
       "      <td>b '' Today I 'm urge the @ CDCgov to immediate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>[(b'Tomorrow, NN), (,, ,), (#, #), (MO03, NNP)...</td>\n",
       "      <td>b'Tomorrow , # MO03 senior graduate from Calva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>[(b'Congrats, NNS), (to, TO), (#, #), (TeamUSA...</td>\n",
       "      <td>b'Congrats to # TeamUSA and Canton Native @ JG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>[(b'Pleased, VBN), (to, TO), (support, VB), (@...</td>\n",
       "      <td>b'Pleased to support @ amergateways at their J...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  b\"RT @KUSINews: One of our longtime viewers wa...   \n",
       "1  b\"Today I'm urging the @CDCgov to immediately ...   \n",
       "2  b'Tomorrow, #MO03 seniors graduate from Calvar...   \n",
       "3  b'Congrats to #TeamUSA and Canton Native @JGre...   \n",
       "4  b'Pleased to support @amergateways at their Ju...   \n",
       "\n",
       "                                       tagged_tokens  \\\n",
       "0  [(b, NN), ('', ''), (RT, NNP), (@, NNP), (KUSI...   \n",
       "1  [(b, NN), ('', ''), (Today, NN), (I, PRP), ('m...   \n",
       "2  [(b'Tomorrow, NN), (,, ,), (#, #), (MO03, NNP)...   \n",
       "3  [(b'Congrats, NNS), (to, TO), (#, #), (TeamUSA...   \n",
       "4  [(b'Pleased, VBN), (to, TO), (support, VB), (@...   \n",
       "\n",
       "                                          lemma_list  \n",
       "0  b '' RT @ KUSINews : One of our longtime viewe...  \n",
       "1  b '' Today I 'm urge the @ CDCgov to immediate...  \n",
       "2  b'Tomorrow , # MO03 senior graduate from Calva...  \n",
       "3  b'Congrats to # TeamUSA and Canton Native @ JG...  \n",
       "4  b'Pleased to support @ amergateways at their J...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce79351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers, words <2 characters, punctuation, links and emojis \n",
    "\n",
    "def emoji_free_text(text): # From [9] \n",
    "    return emoji.get_emoji_regexp().sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e467cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        lower_token = token.lower()\n",
    "        len_check = len(lower_token) >= 2\n",
    "        #start_check = not (lower_token.startswith('http') or lower_token.startswith('\\\\') or lower_token.startswith(':'))\n",
    "        stop_word_check = lower_token not in stop_words\n",
    "        if len_check and stop_word_check:\n",
    "            lower_token=re.sub(r'\\d+', '', lower_token) \n",
    "            lower_token=re.sub(r'\\b\\w{1}\\b', '',  lower_token)  \n",
    "            lower_token=re.sub(r'[^\\w\\s]', '', lower_token)                 # Remove punctuation\n",
    "            lower_token=re.sub(r'http\\S+', '',lower_token)                 # Remove links\n",
    "            cleaned_tokens.append(re.sub('[,.!?]|<br \\/>\\+|<br \\/>', '', lower_token))\n",
    "    return ' '.join(cleaned_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a7ca10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gokha\\AppData\\Local\\Temp/ipykernel_66460/531451104.py:4: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
      "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
      "  return emoji.get_emoji_regexp().sub(r'', text)\n"
     ]
    }
   ],
   "source": [
    "Text_clean = x['lemma_list'].map(clean_text)\n",
    "Text_cleaner = Text_clean .map(emoji_free_text)\n",
    "data_train['text_clean']=Text_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bec656d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party_id</th>\n",
       "      <th>party_class</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>KUSI</td>\n",
       "      <td>10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>rt kusinews one longtime viewer congressman d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>111</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>today  urge cdcgov immediately launch  phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>MO03</td>\n",
       "      <td>2</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>tomorrow mo senior graduate calvary lutheran f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>TeamUSA WorldJuniors</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>congrats teamusa canton native jgreenway win w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>ImmigrantHeritageMonth</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>pleased support amergateways june fiesta honor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   favorite_count                                          full_text  \\\n",
       "0               0  b\"RT @KUSINews: One of our longtime viewers wa...   \n",
       "1             258  b\"Today I'm urging the @CDCgov to immediately ...   \n",
       "2               0  b'Tomorrow, #MO03 seniors graduate from Calvar...   \n",
       "3               9  b'Congrats to #TeamUSA and Canton Native @JGre...   \n",
       "4               3  b'Pleased to support @amergateways at their Ju...   \n",
       "\n",
       "                 hashtags  retweet_count    year party_id  party_class  \\\n",
       "0                    KUSI             10  2017.0        R            1   \n",
       "1             Coronavirus            111  2020.0        R            1   \n",
       "2                    MO03              2  2014.0        R            1   \n",
       "3    TeamUSA WorldJuniors              3  2017.0        R            1   \n",
       "4  ImmigrantHeritageMonth              3  2019.0        D            0   \n",
       "\n",
       "                                          text_clean  \n",
       "0   rt kusinews one longtime viewer congressman d...  \n",
       "1   today  urge cdcgov immediately launch  phone ...  \n",
       "2  tomorrow mo senior graduate calvary lutheran f...  \n",
       "3  congrats teamusa canton native jgreenway win w...  \n",
       "4  pleased support amergateways june fiesta honor...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f18119ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning test data set\n",
    "\n",
    "# test datasindaki naleri de silecek miyiz?\n",
    "\n",
    "# Tokenize\n",
    "tokens_list_test=[word_tokenize(sent) for sent in data_test['full_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "243cfe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pos Tag \n",
    "tagged_tokens_test =[pos_tag(sent) for sent in tokens_list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d3856d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=pd.DataFrame(data_test['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4903a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2['tagged_tokens_test']=tagged_tokens_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c87f3a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_list_test = x2['tagged_tokens_test'].transform(lambda value: ' '.join([lemmatizer.lemmatize(a[0],pos=get_wordnet_pos(a[1])) if get_wordnet_pos(a[1]) else a[0] for a in  value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d12484e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2['lemma_list_test']=lemma_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5a65377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gokha\\AppData\\Local\\Temp/ipykernel_66460/531451104.py:4: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
      "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
      "  return emoji.get_emoji_regexp().sub(r'', text)\n"
     ]
    }
   ],
   "source": [
    "Text_clean_test = x2['lemma_list_test'].map(clean_text)\n",
    "Text_cleaner_test = Text_clean_test .map(emoji_free_text)\n",
    "data_test['text_clean_test']=Text_cleaner_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44b52f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "      <th>party_class</th>\n",
       "      <th>text_clean_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>b'#TaxReform improved the playing field for Am...</td>\n",
       "      <td>TaxReform</td>\n",
       "      <td>13</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>rt kusinews one longtime viewer congressman d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>b'This #NativeWomensEqualPay Day, we recommit ...</td>\n",
       "      <td>NativeWomensEqualPay</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>today  urge cdcgov immediately launch  phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>b\"\\xe2\\x80\\x9cI became convinced that our gene...</td>\n",
       "      <td>MeToo ShatteringTheSilence</td>\n",
       "      <td>24</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>tomorrow mo senior graduate calvary lutheran f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>b'During #NationalAdoptionMonth, we honor the ...</td>\n",
       "      <td>NationalAdoptionMonth</td>\n",
       "      <td>2</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>congrats teamusa canton native jgreenway win w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>b'Happy #AirborneDay to our @USArmy paratroope...</td>\n",
       "      <td>AirborneDay AirborneAllTheWay</td>\n",
       "      <td>7</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>pleased support amergateways june fiesta honor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264995</th>\n",
       "      <td>264995</td>\n",
       "      <td>516</td>\n",
       "      <td>b'We need to #ExtendCHIP before a single child...</td>\n",
       "      <td>ExtendCHIP</td>\n",
       "      <td>223</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>unacceptable florida state quarter hispanic l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264996</th>\n",
       "      <td>264996</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Our #ObamaCare investigation continued today...</td>\n",
       "      <td>ObamaCare</td>\n",
       "      <td>3</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>an open internet vital st century economy fcc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264997</th>\n",
       "      <td>264997</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Congratulations to the new #MissTeenUSA Loga...</td>\n",
       "      <td>MissTeenUSA CT</td>\n",
       "      <td>4</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>icymi need designate certain mexican drug cart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264998</th>\n",
       "      <td>264998</td>\n",
       "      <td>2174</td>\n",
       "      <td>b'Speaking of dishonesty. Nothing like being c...</td>\n",
       "      <td>mosen</td>\n",
       "      <td>1168</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>looking forward hear potus speak congress plan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264999</th>\n",
       "      <td>264999</td>\n",
       "      <td>6</td>\n",
       "      <td>b'In honor of #ConstitutionDay, we remember th...</td>\n",
       "      <td>ConstitutionDay</td>\n",
       "      <td>3</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>washington times president already amend delay...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  favorite_count  \\\n",
       "0            0              70   \n",
       "1            1              27   \n",
       "2            2              49   \n",
       "3            3              14   \n",
       "4            4              13   \n",
       "...        ...             ...   \n",
       "264995  264995             516   \n",
       "264996  264996               0   \n",
       "264997  264997               1   \n",
       "264998  264998            2174   \n",
       "264999  264999               6   \n",
       "\n",
       "                                                full_text  \\\n",
       "0       b'#TaxReform improved the playing field for Am...   \n",
       "1       b'This #NativeWomensEqualPay Day, we recommit ...   \n",
       "2       b\"\\xe2\\x80\\x9cI became convinced that our gene...   \n",
       "3       b'During #NationalAdoptionMonth, we honor the ...   \n",
       "4       b'Happy #AirborneDay to our @USArmy paratroope...   \n",
       "...                                                   ...   \n",
       "264995  b'We need to #ExtendCHIP before a single child...   \n",
       "264996  b\"Our #ObamaCare investigation continued today...   \n",
       "264997  b'Congratulations to the new #MissTeenUSA Loga...   \n",
       "264998  b'Speaking of dishonesty. Nothing like being c...   \n",
       "264999  b'In honor of #ConstitutionDay, we remember th...   \n",
       "\n",
       "                             hashtags  retweet_count    year party  \\\n",
       "0                           TaxReform             13  2018.0     D   \n",
       "1                NativeWomensEqualPay             11     NaN     D   \n",
       "2          MeToo ShatteringTheSilence             24  2017.0     D   \n",
       "3               NationalAdoptionMonth              2  2019.0     D   \n",
       "4       AirborneDay AirborneAllTheWay              7  2018.0     D   \n",
       "...                               ...            ...     ...   ...   \n",
       "264995                     ExtendCHIP            223  2017.0     D   \n",
       "264996                      ObamaCare              3  2013.0     D   \n",
       "264997                 MissTeenUSA CT              4  2012.0     D   \n",
       "264998                          mosen           1168  2018.0     D   \n",
       "264999                ConstitutionDay              3  2015.0     D   \n",
       "\n",
       "        party_class                                    text_clean_test  \n",
       "0                 0   rt kusinews one longtime viewer congressman d...  \n",
       "1                 0   today  urge cdcgov immediately launch  phone ...  \n",
       "2                 0  tomorrow mo senior graduate calvary lutheran f...  \n",
       "3                 0  congrats teamusa canton native jgreenway win w...  \n",
       "4                 0  pleased support amergateways june fiesta honor...  \n",
       "...             ...                                                ...  \n",
       "264995            0   unacceptable florida state quarter hispanic l...  \n",
       "264996            0  an open internet vital st century economy fcc ...  \n",
       "264997            0  icymi need designate certain mexican drug cart...  \n",
       "264998            0  looking forward hear potus speak congress plan...  \n",
       "264999            0  washington times president already amend delay...  \n",
       "\n",
       "[265000 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200535c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
