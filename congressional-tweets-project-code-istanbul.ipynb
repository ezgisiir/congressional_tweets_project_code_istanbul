{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Kaggle Project**\n",
    "## **Irem Nesli Erez & Ezgi Siir Kibris**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-04T14:57:09.653499Z",
     "iopub.status.busy": "2022-04-04T14:57:09.652754Z",
     "iopub.status.idle": "2022-04-04T14:57:09.668938Z",
     "shell.execute_reply": "2022-04-04T14:57:09.668035Z",
     "shell.execute_reply.started": "2022-04-04T14:57:09.653380Z"
    }
   },
   "outputs": [],
   "source": [
    "# This section of the code is added by default.\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:33:21.468706Z",
     "iopub.status.busy": "2022-04-04T15:33:21.467598Z",
     "iopub.status.idle": "2022-04-04T15:33:21.475794Z",
     "shell.execute_reply": "2022-04-04T15:33:21.474920Z",
     "shell.execute_reply.started": "2022-04-04T15:33:21.468643Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "\n",
    "import nltk #language processing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer #for bag of words\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "\n",
    "path = '/Users/nesli/Desktop/SPRING 2022/DSCC 465/Kaggle_istanbul/'\n",
    "os.chdir(path)\n",
    "\n",
    "import random\n",
    "random.seed(465) #seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T14:57:10.394242Z",
     "iopub.status.busy": "2022-04-04T14:57:10.394025Z",
     "iopub.status.idle": "2022-04-04T14:57:12.647660Z",
     "shell.execute_reply": "2022-04-04T14:57:12.646729Z",
     "shell.execute_reply.started": "2022-04-04T14:57:10.394215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>KUSI</td>\n",
       "      <td>10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>111</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>MO03</td>\n",
       "      <td>2</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>TeamUSA WorldJuniors</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>ImmigrantHeritageMonth</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592798</th>\n",
       "      <td>3</td>\n",
       "      <td>b'This time, it focused on careers in #publics...</td>\n",
       "      <td>publicservice publicsafety</td>\n",
       "      <td>0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592799</th>\n",
       "      <td>5</td>\n",
       "      <td>b'.#StormyDaniels, #MichaelWolfe, #JamesComey ...</td>\n",
       "      <td>StormyDaniels MichaelWolfe JamesComey</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592800</th>\n",
       "      <td>33</td>\n",
       "      <td>b'@NRDems The American people deserve the trut...</td>\n",
       "      <td>CultureOfCorruption</td>\n",
       "      <td>14</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592801</th>\n",
       "      <td>4</td>\n",
       "      <td>b'Only 2 weeks left to submit your #app to the...</td>\n",
       "      <td>app copolitics CAC16 HouseOfCode co06</td>\n",
       "      <td>3</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592802</th>\n",
       "      <td>155</td>\n",
       "      <td>b'The #MuslimBan remains as un-American and of...</td>\n",
       "      <td>MuslimBan</td>\n",
       "      <td>48</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>592803 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        favorite_count                                          full_text  \\\n",
       "0                    0  b\"RT @KUSINews: One of our longtime viewers wa...   \n",
       "1                  258  b\"Today I'm urging the @CDCgov to immediately ...   \n",
       "2                    0  b'Tomorrow, #MO03 seniors graduate from Calvar...   \n",
       "3                    9  b'Congrats to #TeamUSA and Canton Native @JGre...   \n",
       "4                    3  b'Pleased to support @amergateways at their Ju...   \n",
       "...                ...                                                ...   \n",
       "592798               3  b'This time, it focused on careers in #publics...   \n",
       "592799               5  b'.#StormyDaniels, #MichaelWolfe, #JamesComey ...   \n",
       "592800              33  b'@NRDems The American people deserve the trut...   \n",
       "592801               4  b'Only 2 weeks left to submit your #app to the...   \n",
       "592802             155  b'The #MuslimBan remains as un-American and of...   \n",
       "\n",
       "                                     hashtags  retweet_count    year party_id  \n",
       "0                                        KUSI             10  2017.0        R  \n",
       "1                                 Coronavirus            111  2020.0        R  \n",
       "2                                        MO03              2  2014.0        R  \n",
       "3                        TeamUSA WorldJuniors              3  2017.0        R  \n",
       "4                      ImmigrantHeritageMonth              3  2019.0        D  \n",
       "...                                       ...            ...     ...      ...  \n",
       "592798             publicservice publicsafety              0  2017.0        R  \n",
       "592799  StormyDaniels MichaelWolfe JamesComey              1  2018.0        R  \n",
       "592800                    CultureOfCorruption             14  2020.0        D  \n",
       "592801  app copolitics CAC16 HouseOfCode co06              3  2016.0        R  \n",
       "592802                              MuslimBan             48  2020.0        D  \n",
       "\n",
       "[592803 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data set\n",
    "data_train = pd.read_csv('congressional_tweet_training_data.csv')\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T14:57:12.648963Z",
     "iopub.status.busy": "2022-04-04T14:57:12.648732Z",
     "iopub.status.idle": "2022-04-04T14:57:13.717922Z",
     "shell.execute_reply": "2022-04-04T14:57:13.716889Z",
     "shell.execute_reply.started": "2022-04-04T14:57:12.648934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>b'#TaxReform improved the playing field for Am...</td>\n",
       "      <td>TaxReform</td>\n",
       "      <td>13</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>b'This #NativeWomensEqualPay Day, we recommit ...</td>\n",
       "      <td>NativeWomensEqualPay</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>b\"\\xe2\\x80\\x9cI became convinced that our gene...</td>\n",
       "      <td>MeToo ShatteringTheSilence</td>\n",
       "      <td>24</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>b'During #NationalAdoptionMonth, we honor the ...</td>\n",
       "      <td>NationalAdoptionMonth</td>\n",
       "      <td>2</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>b'Happy #AirborneDay to our @USArmy paratroope...</td>\n",
       "      <td>AirborneDay AirborneAllTheWay</td>\n",
       "      <td>7</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264995</th>\n",
       "      <td>264995</td>\n",
       "      <td>516</td>\n",
       "      <td>b'We need to #ExtendCHIP before a single child...</td>\n",
       "      <td>ExtendCHIP</td>\n",
       "      <td>223</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264996</th>\n",
       "      <td>264996</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Our #ObamaCare investigation continued today...</td>\n",
       "      <td>ObamaCare</td>\n",
       "      <td>3</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264997</th>\n",
       "      <td>264997</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Congratulations to the new #MissTeenUSA Loga...</td>\n",
       "      <td>MissTeenUSA CT</td>\n",
       "      <td>4</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264998</th>\n",
       "      <td>264998</td>\n",
       "      <td>2174</td>\n",
       "      <td>b'Speaking of dishonesty. Nothing like being c...</td>\n",
       "      <td>mosen</td>\n",
       "      <td>1168</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264999</th>\n",
       "      <td>264999</td>\n",
       "      <td>6</td>\n",
       "      <td>b'In honor of #ConstitutionDay, we remember th...</td>\n",
       "      <td>ConstitutionDay</td>\n",
       "      <td>3</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  favorite_count  \\\n",
       "0            0              70   \n",
       "1            1              27   \n",
       "2            2              49   \n",
       "3            3              14   \n",
       "4            4              13   \n",
       "...        ...             ...   \n",
       "264995  264995             516   \n",
       "264996  264996               0   \n",
       "264997  264997               1   \n",
       "264998  264998            2174   \n",
       "264999  264999               6   \n",
       "\n",
       "                                                full_text  \\\n",
       "0       b'#TaxReform improved the playing field for Am...   \n",
       "1       b'This #NativeWomensEqualPay Day, we recommit ...   \n",
       "2       b\"\\xe2\\x80\\x9cI became convinced that our gene...   \n",
       "3       b'During #NationalAdoptionMonth, we honor the ...   \n",
       "4       b'Happy #AirborneDay to our @USArmy paratroope...   \n",
       "...                                                   ...   \n",
       "264995  b'We need to #ExtendCHIP before a single child...   \n",
       "264996  b\"Our #ObamaCare investigation continued today...   \n",
       "264997  b'Congratulations to the new #MissTeenUSA Loga...   \n",
       "264998  b'Speaking of dishonesty. Nothing like being c...   \n",
       "264999  b'In honor of #ConstitutionDay, we remember th...   \n",
       "\n",
       "                             hashtags  retweet_count    year party  \n",
       "0                           TaxReform             13  2018.0     D  \n",
       "1                NativeWomensEqualPay             11     NaN     D  \n",
       "2          MeToo ShatteringTheSilence             24  2017.0     D  \n",
       "3               NationalAdoptionMonth              2  2019.0     D  \n",
       "4       AirborneDay AirborneAllTheWay              7  2018.0     D  \n",
       "...                               ...            ...     ...   ...  \n",
       "264995                     ExtendCHIP            223  2017.0     D  \n",
       "264996                      ObamaCare              3  2013.0     D  \n",
       "264997                 MissTeenUSA CT              4  2012.0     D  \n",
       "264998                          mosen           1168  2018.0     D  \n",
       "264999                ConstitutionDay              3  2015.0     D  \n",
       "\n",
       "[265000 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data set\n",
    "data_test = pd.read_csv('congressional_tweet_test_data.csv')\n",
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kodu hizlandirmak icin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>KUSI</td>\n",
       "      <td>10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>111</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>MO03</td>\n",
       "      <td>2</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>TeamUSA WorldJuniors</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>ImmigrantHeritageMonth</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>35</td>\n",
       "      <td>b'In 5 years of DACA, over 780,000 #DREAMers h...</td>\n",
       "      <td>DREAMers SaveDACA</td>\n",
       "      <td>17</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>118</td>\n",
       "      <td>b'Over 90% of gun owners support expanding bac...</td>\n",
       "      <td>OutShoutTheGunLobby</td>\n",
       "      <td>39</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>26</td>\n",
       "      <td>b'Holi is a time to celebrate renewal &amp;amp; a ...</td>\n",
       "      <td>Holi2015</td>\n",
       "      <td>21</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>78</td>\n",
       "      <td>b'Connecticut\\xe2\\x80\\x99s 4th District lost t...</td>\n",
       "      <td>911remembrance</td>\n",
       "      <td>6</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6</td>\n",
       "      <td>b'Always great catching up with @GlennVaagen @...</td>\n",
       "      <td>FarmBill WA04</td>\n",
       "      <td>2</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    favorite_count                                          full_text  \\\n",
       "0                0  b\"RT @KUSINews: One of our longtime viewers wa...   \n",
       "1              258  b\"Today I'm urging the @CDCgov to immediately ...   \n",
       "2                0  b'Tomorrow, #MO03 seniors graduate from Calvar...   \n",
       "3                9  b'Congrats to #TeamUSA and Canton Native @JGre...   \n",
       "4                3  b'Pleased to support @amergateways at their Ju...   \n",
       "..             ...                                                ...   \n",
       "95              35  b'In 5 years of DACA, over 780,000 #DREAMers h...   \n",
       "96             118  b'Over 90% of gun owners support expanding bac...   \n",
       "97              26  b'Holi is a time to celebrate renewal &amp; a ...   \n",
       "98              78  b'Connecticut\\xe2\\x80\\x99s 4th District lost t...   \n",
       "99               6  b'Always great catching up with @GlennVaagen @...   \n",
       "\n",
       "                  hashtags  retweet_count    year party_id  \n",
       "0                     KUSI             10  2017.0        R  \n",
       "1              Coronavirus            111  2020.0        R  \n",
       "2                     MO03              2  2014.0        R  \n",
       "3     TeamUSA WorldJuniors              3  2017.0        R  \n",
       "4   ImmigrantHeritageMonth              3  2019.0        D  \n",
       "..                     ...            ...     ...      ...  \n",
       "95       DREAMers SaveDACA             17  2017.0        D  \n",
       "96     OutShoutTheGunLobby             39  2017.0        D  \n",
       "97                Holi2015             21  2015.0        D  \n",
       "98          911remembrance              6  2018.0        D  \n",
       "99           FarmBill WA04              2  2018.0        R  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=data_train[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=data_test[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "First, preprocess the full_text feature of the tweets for both test and the train data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T14:57:13.720090Z",
     "iopub.status.busy": "2022-04-04T14:57:13.719750Z",
     "iopub.status.idle": "2022-04-04T14:57:13.725507Z",
     "shell.execute_reply": "2022-04-04T14:57:13.724553Z",
     "shell.execute_reply.started": "2022-04-04T14:57:13.720056Z"
    }
   },
   "outputs": [],
   "source": [
    "#Code from HW4 CITE IT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T14:57:13.727638Z",
     "iopub.status.busy": "2022-04-04T14:57:13.727298Z",
     "iopub.status.idle": "2022-04-04T14:57:13.926808Z",
     "shell.execute_reply": "2022-04-04T14:57:13.925918Z",
     "shell.execute_reply.started": "2022-04-04T14:57:13.727596Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nesli/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>KUSI</td>\n",
       "      <td>10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>111</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>MO03</td>\n",
       "      <td>2</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>TeamUSA WorldJuniors</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>ImmigrantHeritageMonth</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>35</td>\n",
       "      <td>b'In 5 years of DACA, over 780,000 #DREAMers h...</td>\n",
       "      <td>DREAMers SaveDACA</td>\n",
       "      <td>17</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>118</td>\n",
       "      <td>b'Over 90% of gun owners support expanding bac...</td>\n",
       "      <td>OutShoutTheGunLobby</td>\n",
       "      <td>39</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>26</td>\n",
       "      <td>b'Holi is a time to celebrate renewal &amp;amp; a ...</td>\n",
       "      <td>Holi2015</td>\n",
       "      <td>21</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>78</td>\n",
       "      <td>b'Connecticut\\xe2\\x80\\x99s 4th District lost t...</td>\n",
       "      <td>911remembrance</td>\n",
       "      <td>6</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6</td>\n",
       "      <td>b'Always great catching up with @GlennVaagen @...</td>\n",
       "      <td>FarmBill WA04</td>\n",
       "      <td>2</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    favorite_count                                          full_text  \\\n",
       "0                0  b\"RT @KUSINews: One of our longtime viewers wa...   \n",
       "1              258  b\"Today I'm urging the @CDCgov to immediately ...   \n",
       "2                0  b'Tomorrow, #MO03 seniors graduate from Calvar...   \n",
       "3                9  b'Congrats to #TeamUSA and Canton Native @JGre...   \n",
       "4                3  b'Pleased to support @amergateways at their Ju...   \n",
       "..             ...                                                ...   \n",
       "95              35  b'In 5 years of DACA, over 780,000 #DREAMers h...   \n",
       "96             118  b'Over 90% of gun owners support expanding bac...   \n",
       "97              26  b'Holi is a time to celebrate renewal &amp; a ...   \n",
       "98              78  b'Connecticut\\xe2\\x80\\x99s 4th District lost t...   \n",
       "99               6  b'Always great catching up with @GlennVaagen @...   \n",
       "\n",
       "                  hashtags  retweet_count    year party_id  \n",
       "0                     KUSI             10  2017.0        R  \n",
       "1              Coronavirus            111  2020.0        R  \n",
       "2                     MO03              2  2014.0        R  \n",
       "3     TeamUSA WorldJuniors              3  2017.0        R  \n",
       "4   ImmigrantHeritageMonth              3  2019.0        D  \n",
       "..                     ...            ...     ...      ...  \n",
       "95       DREAMers SaveDACA             17  2017.0        D  \n",
       "96     OutShoutTheGunLobby             39  2017.0        D  \n",
       "97                Holi2015             21  2015.0        D  \n",
       "98          911remembrance              6  2018.0        D  \n",
       "99           FarmBill WA04              2  2018.0        R  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start by cleaning the full text of the tweets \n",
    "data_train.dropna(subset=['full_text'],inplace=True) #First, I drop the rows with NA in the text column\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T14:57:13.928645Z",
     "iopub.status.busy": "2022-04-04T14:57:13.928183Z",
     "iopub.status.idle": "2022-04-04T14:57:13.969991Z",
     "shell.execute_reply": "2022-04-04T14:57:13.968979Z",
     "shell.execute_reply.started": "2022-04-04T14:57:13.928599Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train=data_train.reset_index(drop=True) #to fix the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T14:57:13.971483Z",
     "iopub.status.busy": "2022-04-04T14:57:13.971241Z"
    }
   },
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "tokens_list=list()\n",
    "for i in np.arange(len(data_train)):\n",
    "    tokens_list.append(nltk.word_tokenize(str(data_train['full_text'][i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2022-04-04T15:20:23.201600Z",
     "shell.execute_reply": "2022-04-04T15:20:23.200668Z",
     "shell.execute_reply.started": "2022-04-04T15:02:47.703855Z"
    }
   },
   "outputs": [],
   "source": [
    "tagged_tokens=list()\n",
    "for i in np.arange(len(tokens_list)):\n",
    "    tagged_tokens.append(nltk.pos_tag(tokens_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:20:23.202919Z",
     "iopub.status.busy": "2022-04-04T15:20:23.202696Z",
     "iopub.status.idle": "2022-04-04T15:20:23.208896Z",
     "shell.execute_reply": "2022-04-04T15:20:23.208015Z",
     "shell.execute_reply.started": "2022-04-04T15:20:23.202891Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag): #Following from [16]\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None # for easy if-statement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:20:23.211832Z",
     "iopub.status.busy": "2022-04-04T15:20:23.211595Z",
     "iopub.status.idle": "2022-04-04T15:20:23.225772Z",
     "shell.execute_reply": "2022-04-04T15:20:23.224761Z",
     "shell.execute_reply.started": "2022-04-04T15:20:23.211802Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:20:23.228080Z",
     "iopub.status.busy": "2022-04-04T15:20:23.227215Z",
     "iopub.status.idle": "2022-04-04T15:22:51.008803Z",
     "shell.execute_reply": "2022-04-04T15:22:51.000812Z",
     "shell.execute_reply.started": "2022-04-04T15:20:23.228023Z"
    }
   },
   "outputs": [],
   "source": [
    "lemma_list=list()\n",
    "\n",
    "for i in np.arange(len(tagged_tokens)):\n",
    "    lemma=list()\n",
    "    for j in np.arange(len(tagged_tokens[i])):\n",
    "        \n",
    "        token=tagged_tokens[i][j][0] \n",
    "        tag=tagged_tokens[i][j][1]\n",
    "        \n",
    "        wntag = get_wordnet_pos(tag)\n",
    "        if wntag is None:           #do not supply tag in case of None\n",
    "            lemma.append(lemmatizer.lemmatize(token))\n",
    "        else:\n",
    "            lemma.append(lemmatizer.lemmatize(token, pos=wntag))\n",
    "    lemma_list.append(lemma)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:22:51.011288Z",
     "iopub.status.busy": "2022-04-04T15:22:51.010682Z",
     "iopub.status.idle": "2022-04-04T15:22:51.017452Z",
     "shell.execute_reply": "2022-04-04T15:22:51.016654Z",
     "shell.execute_reply.started": "2022-04-04T15:22:51.011242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:22:51.019567Z",
     "iopub.status.busy": "2022-04-04T15:22:51.018949Z",
     "iopub.status.idle": "2022-04-04T15:23:08.107810Z",
     "shell.execute_reply": "2022-04-04T15:23:08.106931Z",
     "shell.execute_reply.started": "2022-04-04T15:22:51.019518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Before removing elements from the string, make all of them lowercase\n",
    "filtered_lower=list()\n",
    "for i in np.arange(len(lemma_list)):\n",
    "    lowered=list()\n",
    "    for j in np.arange(len(lemma_list[i])):\n",
    "        lowered.append(lemma_list[i][j].lower())\n",
    "    filtered_lower.append(lowered)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:23:08.109184Z",
     "iopub.status.busy": "2022-04-04T15:23:08.108958Z",
     "iopub.status.idle": "2022-04-04T15:23:08.116869Z",
     "shell.execute_reply": "2022-04-04T15:23:08.116223Z",
     "shell.execute_reply.started": "2022-04-04T15:23:08.109155Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now to remove stop words like 'the', 'a', 'and' \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:23:08.118365Z",
     "iopub.status.busy": "2022-04-04T15:23:08.118093Z",
     "iopub.status.idle": "2022-04-04T15:23:13.144102Z",
     "shell.execute_reply": "2022-04-04T15:23:13.143264Z",
     "shell.execute_reply.started": "2022-04-04T15:23:08.118338Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_list=list()\n",
    "for i in np.arange(len(filtered_lower)):\n",
    "    filtered_list.append([w for w in filtered_lower[i] if not w.lower() in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:23:13.145441Z",
     "iopub.status.busy": "2022-04-04T15:23:13.145222Z",
     "iopub.status.idle": "2022-04-04T15:23:13.151378Z",
     "shell.execute_reply": "2022-04-04T15:23:13.150400Z",
     "shell.execute_reply.started": "2022-04-04T15:23:13.145415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:23:13.152626Z",
     "iopub.status.busy": "2022-04-04T15:23:13.152410Z",
     "iopub.status.idle": "2022-04-04T15:23:13.167146Z",
     "shell.execute_reply": "2022-04-04T15:23:13.166505Z",
     "shell.execute_reply.started": "2022-04-04T15:23:13.152598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove numbers, words <2 characters, punctuation, links and emojis \n",
    "\n",
    "def emoji_free_text(text): # From [9]\n",
    "    return emoji.get_emoji_regexp().sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:23:13.168539Z",
     "iopub.status.busy": "2022-04-04T15:23:13.168144Z",
     "iopub.status.idle": "2022-04-04T15:33:20.402953Z",
     "shell.execute_reply": "2022-04-04T15:33:20.402036Z",
     "shell.execute_reply.started": "2022-04-04T15:23:13.168490Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_elements=list()\n",
    "\n",
    "for i in np.arange(len(filtered_list)):\n",
    "    filter_element=list()\n",
    "    for j in np.arange(len(filtered_list[i])):\n",
    "        \n",
    "        element=re.sub(r'\\d+', '',filtered_list[i][j])          # Remove numbers\n",
    "        element=re.sub(r'\\b\\w{1}\\b', '', element)               # Remove <2 characters\n",
    "        element=re.sub(r'[^\\w\\s]', '', element)                 # Remove punctuation\n",
    "        element=re.sub(r'http\\S+', '', element)                 # Remove links\n",
    "        #element=re.sub('/[\\u{1f300}-\\u{1f5ff}]/', '', element) # Remove symbols\n",
    "        #element=re.sub('/[\\u{1f600}-\\u{1f64f}]/','', element)  # Remove emoticons\n",
    "        emoji_free_text(element)\n",
    "        \n",
    "        filter_element.append(element)\n",
    "    filtered_elements.append(filter_element)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:33:20.404974Z",
     "iopub.status.busy": "2022-04-04T15:33:20.404639Z",
     "iopub.status.idle": "2022-04-04T15:33:21.337526Z",
     "shell.execute_reply": "2022-04-04T15:33:21.336563Z",
     "shell.execute_reply.started": "2022-04-04T15:33:20.404931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine the elements back to form sentences\n",
    "text_clean_list=list()\n",
    "s=' '\n",
    "\n",
    "for i in np.arange(len(filtered_elements)):\n",
    "    text_clean_list.append(s.join(filtered_elements[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:33:21.339193Z",
     "iopub.status.busy": "2022-04-04T15:33:21.338960Z",
     "iopub.status.idle": "2022-04-04T15:33:21.344807Z",
     "shell.execute_reply": "2022-04-04T15:33:21.344232Z",
     "shell.execute_reply.started": "2022-04-04T15:33:21.339166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:33:21.346392Z",
     "iopub.status.busy": "2022-04-04T15:33:21.346022Z",
     "iopub.status.idle": "2022-04-04T15:33:21.422649Z",
     "shell.execute_reply": "2022-04-04T15:33:21.421889Z",
     "shell.execute_reply.started": "2022-04-04T15:33:21.346349Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add a new column of 'text_clean'\n",
    "data_train.insert(6, \"text_clean\", text_clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:33:21.424448Z",
     "iopub.status.busy": "2022-04-04T15:33:21.423954Z",
     "iopub.status.idle": "2022-04-04T15:33:21.439756Z",
     "shell.execute_reply": "2022-04-04T15:33:21.438703Z",
     "shell.execute_reply.started": "2022-04-04T15:33:21.424417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party_id</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>KUSI</td>\n",
       "      <td>10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "      <td>rt  kusinews  one longtime viewer congressma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>111</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>R</td>\n",
       "      <td>today  urge  cdcgov immediately launch  phon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>MO03</td>\n",
       "      <td>2</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>R</td>\n",
       "      <td>tomorrow   mo senior graduate calvary lutheran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>TeamUSA WorldJuniors</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "      <td>congrats  teamusa canton native  jgreenway win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>ImmigrantHeritageMonth</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "      <td>pleased support  amergateways june fiesta  hon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   favorite_count                                          full_text  \\\n",
       "0               0  b\"RT @KUSINews: One of our longtime viewers wa...   \n",
       "1             258  b\"Today I'm urging the @CDCgov to immediately ...   \n",
       "2               0  b'Tomorrow, #MO03 seniors graduate from Calvar...   \n",
       "3               9  b'Congrats to #TeamUSA and Canton Native @JGre...   \n",
       "4               3  b'Pleased to support @amergateways at their Ju...   \n",
       "\n",
       "                 hashtags  retweet_count    year party_id  \\\n",
       "0                    KUSI             10  2017.0        R   \n",
       "1             Coronavirus            111  2020.0        R   \n",
       "2                    MO03              2  2014.0        R   \n",
       "3    TeamUSA WorldJuniors              3  2017.0        R   \n",
       "4  ImmigrantHeritageMonth              3  2019.0        D   \n",
       "\n",
       "                                          text_clean  \n",
       "0    rt  kusinews  one longtime viewer congressma...  \n",
       "1    today  urge  cdcgov immediately launch  phon...  \n",
       "2  tomorrow   mo senior graduate calvary lutheran...  \n",
       "3  congrats  teamusa canton native  jgreenway win...  \n",
       "4  pleased support  amergateways june fiesta  hon...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nesli/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>b'#TaxReform improved the playing field for Am...</td>\n",
       "      <td>TaxReform</td>\n",
       "      <td>13</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>b'This #NativeWomensEqualPay Day, we recommit ...</td>\n",
       "      <td>NativeWomensEqualPay</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>b\"\\xe2\\x80\\x9cI became convinced that our gene...</td>\n",
       "      <td>MeToo ShatteringTheSilence</td>\n",
       "      <td>24</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>b'During #NationalAdoptionMonth, we honor the ...</td>\n",
       "      <td>NationalAdoptionMonth</td>\n",
       "      <td>2</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>b'Happy #AirborneDay to our @USArmy paratroope...</td>\n",
       "      <td>AirborneDay AirborneAllTheWay</td>\n",
       "      <td>7</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>66</td>\n",
       "      <td>b\"I've never been more confused in my life. An...</td>\n",
       "      <td>whiteandgold blackandblue</td>\n",
       "      <td>78</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>678</td>\n",
       "      <td>b'This is progress #coronarvirus https://t.co/...</td>\n",
       "      <td>coronarvirus</td>\n",
       "      <td>224</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>b'.@HouseGOP voted to reduce child care access...</td>\n",
       "      <td>WEmatter</td>\n",
       "      <td>11</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Our Army is equally ready to assist in a dis...</td>\n",
       "      <td>MilitaryMonday</td>\n",
       "      <td>0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>28</td>\n",
       "      <td>b'There is no racial justice without environme...</td>\n",
       "      <td>COVID19</td>\n",
       "      <td>14</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  favorite_count                                          full_text  \\\n",
       "0    0              70  b'#TaxReform improved the playing field for Am...   \n",
       "1    1              27  b'This #NativeWomensEqualPay Day, we recommit ...   \n",
       "2    2              49  b\"\\xe2\\x80\\x9cI became convinced that our gene...   \n",
       "3    3              14  b'During #NationalAdoptionMonth, we honor the ...   \n",
       "4    4              13  b'Happy #AirborneDay to our @USArmy paratroope...   \n",
       "..  ..             ...                                                ...   \n",
       "95  95              66  b\"I've never been more confused in my life. An...   \n",
       "96  96             678  b'This is progress #coronarvirus https://t.co/...   \n",
       "97  97               5  b'.@HouseGOP voted to reduce child care access...   \n",
       "98  98               0  b'Our Army is equally ready to assist in a dis...   \n",
       "99  99              28  b'There is no racial justice without environme...   \n",
       "\n",
       "                         hashtags  retweet_count    year party  \n",
       "0                       TaxReform             13  2018.0     D  \n",
       "1            NativeWomensEqualPay             11     NaN     D  \n",
       "2      MeToo ShatteringTheSilence             24  2017.0     D  \n",
       "3           NationalAdoptionMonth              2  2019.0     D  \n",
       "4   AirborneDay AirborneAllTheWay              7  2018.0     D  \n",
       "..                            ...            ...     ...   ...  \n",
       "95      whiteandgold blackandblue             78  2015.0     D  \n",
       "96                   coronarvirus            224  2020.0     D  \n",
       "97                       WEmatter             11  2014.0     D  \n",
       "98                 MilitaryMonday              0  2016.0     D  \n",
       "99                        COVID19             14  2020.0     D  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat the same for the test data\n",
    "\n",
    "# Start by cleaning the full text of the tweets \n",
    "data_test.dropna(subset=['full_text'],inplace=True) #First, I drop the rows with NA in the text column\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=data_test.reset_index(drop=True) #to fix the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "tokens_list=list()\n",
    "for i in np.arange(len(data_test)):\n",
    "    tokens_list.append(nltk.word_tokenize(str(data_test['full_text'][i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_tokens=list()\n",
    "for i in np.arange(len(tokens_list)):\n",
    "    tagged_tokens.append(nltk.pos_tag(tokens_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag): #Following from [16]\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None # for easy if-statement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_list=list()\n",
    "\n",
    "for i in np.arange(len(tagged_tokens)):\n",
    "    lemma=list()\n",
    "    for j in np.arange(len(tagged_tokens[i])):\n",
    "        \n",
    "        token=tagged_tokens[i][j][0] \n",
    "        tag=tagged_tokens[i][j][1]\n",
    "        \n",
    "        wntag = get_wordnet_pos(tag)\n",
    "        if wntag is None:           #do not supply tag in case of None\n",
    "            lemma.append(lemmatizer.lemmatize(token))\n",
    "        else:\n",
    "            lemma.append(lemmatizer.lemmatize(token, pos=wntag))\n",
    "    lemma_list.append(lemma)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before removing elements from the string, make all of them lowercase\n",
    "filtered_lower=list()\n",
    "for i in np.arange(len(lemma_list)):\n",
    "    lowered=list()\n",
    "    for j in np.arange(len(lemma_list[i])):\n",
    "        lowered.append(lemma_list[i][j].lower())\n",
    "    filtered_lower.append(lowered)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to remove stop words like 'the', 'a', 'and' \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list=list()\n",
    "for i in np.arange(len(filtered_lower)):\n",
    "    filtered_list.append([w for w in filtered_lower[i] if not w.lower() in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers, words <2 characters, punctuation, links and emojis \n",
    "\n",
    "def emoji_free_text(text): # From [9]\n",
    "    return emoji.get_emoji_regexp().sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_elements=list()\n",
    "\n",
    "for i in np.arange(len(filtered_list)):\n",
    "    filter_element=list()\n",
    "    for j in np.arange(len(filtered_list[i])):\n",
    "        \n",
    "        element=re.sub(r'\\d+', '',filtered_list[i][j])          # Remove numbers\n",
    "        element=re.sub(r'\\b\\w{1}\\b', '', element)               # Remove <2 characters\n",
    "        element=re.sub(r'[^\\w\\s]', '', element)                 # Remove punctuation\n",
    "        element=re.sub(r'http\\S+', '', element)                 # Remove links\n",
    "        #element=re.sub('/[\\u{1f300}-\\u{1f5ff}]/', '', element) # Remove symbols\n",
    "        #element=re.sub('/[\\u{1f600}-\\u{1f64f}]/','', element)  # Remove emoticons\n",
    "        emoji_free_text(element)\n",
    "        \n",
    "        filter_element.append(element)\n",
    "    filtered_elements.append(filter_element)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the elements back to form sentences\n",
    "text_clean_list=list()\n",
    "s=' '\n",
    "\n",
    "for i in np.arange(len(filtered_elements)):\n",
    "    text_clean_list.append(s.join(filtered_elements[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column of 'text_clean'\n",
    "data_test.insert(7, \"text_clean\", text_clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>b'#TaxReform improved the playing field for Am...</td>\n",
       "      <td>TaxReform</td>\n",
       "      <td>13</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "      <td>taxreform improve playing field american wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>b'This #NativeWomensEqualPay Day, we recommit ...</td>\n",
       "      <td>NativeWomensEqualPay</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>this  nativewomensequalpay day  recommit pass ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>b\"\\xe2\\x80\\x9cI became convinced that our gene...</td>\n",
       "      <td>MeToo ShatteringTheSilence</td>\n",
       "      <td>24</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "      <td>xexci become convinced generation silence ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>b'During #NationalAdoptionMonth, we honor the ...</td>\n",
       "      <td>NationalAdoptionMonth</td>\n",
       "      <td>2</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "      <td>during  nationaladoptionmonth  honor adoptive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>b'Happy #AirborneDay to our @USArmy paratroope...</td>\n",
       "      <td>AirborneDay AirborneAllTheWay</td>\n",
       "      <td>7</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "      <td>happy  airborneday  usarmy paratrooper veteran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  favorite_count                                          full_text  \\\n",
       "0   0              70  b'#TaxReform improved the playing field for Am...   \n",
       "1   1              27  b'This #NativeWomensEqualPay Day, we recommit ...   \n",
       "2   2              49  b\"\\xe2\\x80\\x9cI became convinced that our gene...   \n",
       "3   3              14  b'During #NationalAdoptionMonth, we honor the ...   \n",
       "4   4              13  b'Happy #AirborneDay to our @USArmy paratroope...   \n",
       "\n",
       "                        hashtags  retweet_count    year party  \\\n",
       "0                      TaxReform             13  2018.0     D   \n",
       "1           NativeWomensEqualPay             11     NaN     D   \n",
       "2     MeToo ShatteringTheSilence             24  2017.0     D   \n",
       "3          NationalAdoptionMonth              2  2019.0     D   \n",
       "4  AirborneDay AirborneAllTheWay              7  2018.0     D   \n",
       "\n",
       "                                          text_clean  \n",
       "0     taxreform improve playing field american wo...  \n",
       "1  this  nativewomensequalpay day  recommit pass ...  \n",
       "2    xexci become convinced generation silence ma...  \n",
       "3  during  nationaladoptionmonth  honor adoptive ...  \n",
       "4  happy  airborneday  usarmy paratrooper veteran...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to deal with shortened words like rt?\n",
    "\n",
    "We could create a dictionary for that, but we assume that the senators(?) use English properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the data\n",
    "\n",
    "Now for vectorization, we can use different techniques. Try two different methods:\n",
    "\n",
    "1. Bag of words\n",
    "2. Word2vec\n",
    "\n",
    "We will not try TF-IDF because it is rather beneficial for long text data.\n",
    "\n",
    "Considering the fact that the bag of words method includes each unique word in the text as a dimension, it is better to apply vectorization on the merged data set that contains both the test and the training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T15:36:42.901919Z",
     "iopub.status.busy": "2022-04-04T15:36:42.900971Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bag of words\n",
    "# Following from [1]\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "text_bow = vectorizer.fit_transform(data_train['text_clean'])\n",
    "text_bow_df = pd.DataFrame(text_bow.toarray(),columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abrams</th>\n",
       "      <th>aca</th>\n",
       "      <th>access</th>\n",
       "      <th>accessibility</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activity</th>\n",
       "      <th>actonclimate</th>\n",
       "      <th>ada</th>\n",
       "      <th>...</th>\n",
       "      <th>xexcmy</th>\n",
       "      <th>xexdxaxefxbxf</th>\n",
       "      <th>xexm</th>\n",
       "      <th>yarnell</th>\n",
       "      <th>year</th>\n",
       "      <th>yorkers</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zika</th>\n",
       "      <th>zumwalt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abrams  aca  access  accessibility  across  act  action  activity  \\\n",
       "0        0    0       0              0       0    0       0         0   \n",
       "1        0    0       0              0       0    0       0         0   \n",
       "2        0    0       0              0       0    0       0         0   \n",
       "3        0    0       0              0       0    0       0         0   \n",
       "4        0    0       0              0       0    0       0         0   \n",
       "..     ...  ...     ...            ...     ...  ...     ...       ...   \n",
       "95       0    0       0              0       0    0       0         0   \n",
       "96       0    0       0              0       0    0       1         0   \n",
       "97       0    0       0              0       0    0       0         0   \n",
       "98       0    0       0              0       0    0       0         0   \n",
       "99       0    0       0              0       0    0       0         0   \n",
       "\n",
       "    actonclimate  ada  ...  xexcmy  xexdxaxefxbxf  xexm  yarnell  year  \\\n",
       "0              0    0  ...       0              0     0        0     0   \n",
       "1              0    0  ...       0              0     0        0     0   \n",
       "2              0    0  ...       0              0     0        0     0   \n",
       "3              0    0  ...       0              0     0        0     0   \n",
       "4              0    0  ...       0              0     0        0     0   \n",
       "..           ...  ...  ...     ...            ...   ...      ...   ...   \n",
       "95             0    0  ...       0              0     0        0     1   \n",
       "96             0    0  ...       0              0     0        0     0   \n",
       "97             0    0  ...       0              0     0        0     0   \n",
       "98             0    0  ...       0              0     0        0     0   \n",
       "99             0    0  ...       0              0     0        0     0   \n",
       "\n",
       "    yorkers  young  youtube  zika  zumwalt  \n",
       "0         0      0        0     0        0  \n",
       "1         0      0        0     0        0  \n",
       "2         0      0        0     0        4  \n",
       "3         0      0        0     0        0  \n",
       "4         0      0        0     0        0  \n",
       "..      ...    ...      ...   ...      ...  \n",
       "95        0      0        0     0        0  \n",
       "96        0      0        0     0        0  \n",
       "97        0      0        0     0        0  \n",
       "98        0      0        0     0        0  \n",
       "99        0      0        0     0        0  \n",
       "\n",
       "[100 rows x 1059 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words\n",
    "# Following from [1]\n",
    "# For the test data\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "text_bow_test = vectorizer.fit_transform(data_test['text_clean'])\n",
    "text_bow__test_df = pd.DataFrame(text_bow_test.toarray(),columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abcnews</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>access</th>\n",
       "      <th>accomplish</th>\n",
       "      <th>accordingly</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>actxexd</th>\n",
       "      <th>...</th>\n",
       "      <th>xfxfxaxa</th>\n",
       "      <th>xfxfxbb</th>\n",
       "      <th>year</th>\n",
       "      <th>yemen</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1050 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abcnews  able  abortion  absolutely  access  accomplish  accordingly  \\\n",
       "0         0     0         0           0       0           0            0   \n",
       "1         0     0         0           0       0           0            0   \n",
       "2         0     0         0           0       0           0            0   \n",
       "3         0     0         0           0       0           0            0   \n",
       "4         0     0         0           0       0           0            0   \n",
       "..      ...   ...       ...         ...     ...         ...          ...   \n",
       "95        0     0         0           0       0           0            0   \n",
       "96        0     0         0           0       0           0            0   \n",
       "97        0     0         0           0       1           0            0   \n",
       "98        0     0         0           0       0           0            0   \n",
       "99        0     0         0           0       0           0            0   \n",
       "\n",
       "    across  act  actxexd  ...  xfxfxaxa  xfxfxbb  year  yemen  yesterday  yet  \\\n",
       "0        0    0        0  ...         0        0     0      0          0    0   \n",
       "1        0    1        0  ...         0        0     0      0          0    0   \n",
       "2        0    0        0  ...         0        0     0      0          0    0   \n",
       "3        0    0        0  ...         0        0     0      0          0    0   \n",
       "4        0    0        0  ...         0        0     0      0          0    0   \n",
       "..     ...  ...      ...  ...       ...      ...   ...    ...        ...  ...   \n",
       "95       0    0        0  ...         0        0     0      0          0    0   \n",
       "96       0    0        0  ...         0        0     0      0          0    0   \n",
       "97       0    0        0  ...         0        0     0      0          0    0   \n",
       "98       0    0        0  ...         0        0     0      0          0    0   \n",
       "99       0    0        0  ...         0        0     0      0          0    0   \n",
       "\n",
       "    young  youth  yr  zero  \n",
       "0       0      0   0     0  \n",
       "1       0      0   0     0  \n",
       "2       0      0   0     0  \n",
       "3       0      1   0     0  \n",
       "4       0      0   0     0  \n",
       "..    ...    ...  ..   ...  \n",
       "95      0      0   0     0  \n",
       "96      0      0   0     0  \n",
       "97      0      0   0     0  \n",
       "98      0      0   0     0  \n",
       "99      0      0   0     0  \n",
       "\n",
       "[100 rows x 1050 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bow__test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we would like the same vectorization to happen for all of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([data_train,data_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party_id</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>Id</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>KUSI</td>\n",
       "      <td>10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "      <td>rt  kusinews  one longtime viewer congressma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>111</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>R</td>\n",
       "      <td>today  urge  cdcgov immediately launch  phon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>MO03</td>\n",
       "      <td>2</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>R</td>\n",
       "      <td>tomorrow   mo senior graduate calvary lutheran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>TeamUSA WorldJuniors</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "      <td>congrats  teamusa canton native  jgreenway win...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>ImmigrantHeritageMonth</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "      <td>pleased support  amergateways june fiesta  hon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>66</td>\n",
       "      <td>b\"I've never been more confused in my life. An...</td>\n",
       "      <td>whiteandgold blackandblue</td>\n",
       "      <td>78</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ve never confused life  ve listen  replouieg...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>678</td>\n",
       "      <td>b'This is progress #coronarvirus https://t.co/...</td>\n",
       "      <td>coronarvirus</td>\n",
       "      <td>224</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this progress  coronarvirus http  cohsplcjy</td>\n",
       "      <td>96.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>5</td>\n",
       "      <td>b'.@HouseGOP voted to reduce child care access...</td>\n",
       "      <td>WEmatter</td>\n",
       "      <td>11</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>housegop vote reduce child care access  de...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Our Army is equally ready to assist in a dis...</td>\n",
       "      <td>MilitaryMonday</td>\n",
       "      <td>0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our army equally ready assist disaster  amp  e...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>28</td>\n",
       "      <td>b'There is no racial justice without environme...</td>\n",
       "      <td>COVID19</td>\n",
       "      <td>14</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there racial justice without environmental  am...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     favorite_count                                          full_text  \\\n",
       "0                 0  b\"RT @KUSINews: One of our longtime viewers wa...   \n",
       "1               258  b\"Today I'm urging the @CDCgov to immediately ...   \n",
       "2                 0  b'Tomorrow, #MO03 seniors graduate from Calvar...   \n",
       "3                 9  b'Congrats to #TeamUSA and Canton Native @JGre...   \n",
       "4                 3  b'Pleased to support @amergateways at their Ju...   \n",
       "..              ...                                                ...   \n",
       "195              66  b\"I've never been more confused in my life. An...   \n",
       "196             678  b'This is progress #coronarvirus https://t.co/...   \n",
       "197               5  b'.@HouseGOP voted to reduce child care access...   \n",
       "198               0  b'Our Army is equally ready to assist in a dis...   \n",
       "199              28  b'There is no racial justice without environme...   \n",
       "\n",
       "                      hashtags  retweet_count    year party_id  \\\n",
       "0                         KUSI             10  2017.0        R   \n",
       "1                  Coronavirus            111  2020.0        R   \n",
       "2                         MO03              2  2014.0        R   \n",
       "3         TeamUSA WorldJuniors              3  2017.0        R   \n",
       "4       ImmigrantHeritageMonth              3  2019.0        D   \n",
       "..                         ...            ...     ...      ...   \n",
       "195  whiteandgold blackandblue             78  2015.0      NaN   \n",
       "196               coronarvirus            224  2020.0      NaN   \n",
       "197                   WEmatter             11  2014.0      NaN   \n",
       "198             MilitaryMonday              0  2016.0      NaN   \n",
       "199                    COVID19             14  2020.0      NaN   \n",
       "\n",
       "                                            text_clean    Id party  \n",
       "0      rt  kusinews  one longtime viewer congressma...   NaN   NaN  \n",
       "1      today  urge  cdcgov immediately launch  phon...   NaN   NaN  \n",
       "2    tomorrow   mo senior graduate calvary lutheran...   NaN   NaN  \n",
       "3    congrats  teamusa canton native  jgreenway win...   NaN   NaN  \n",
       "4    pleased support  amergateways june fiesta  hon...   NaN   NaN  \n",
       "..                                                 ...   ...   ...  \n",
       "195    ve never confused life  ve listen  replouieg...  95.0     D  \n",
       "196       this progress  coronarvirus http  cohsplcjy   96.0     D  \n",
       "197      housegop vote reduce child care access  de...  97.0     D  \n",
       "198  our army equally ready assist disaster  amp  e...  98.0     D  \n",
       "199  there racial justice without environmental  am...  99.0     D  \n",
       "\n",
       "[200 rows x 9 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words\n",
    "# Following from [1]\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "text_bow = vectorizer.fit_transform(data['text_clean'])\n",
    "text_bow_df = pd.DataFrame(text_bow.toarray(),columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abcnews</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abrams</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>aca</th>\n",
       "      <th>access</th>\n",
       "      <th>accessibility</th>\n",
       "      <th>accomplish</th>\n",
       "      <th>accordingly</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yorkers</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "      <th>zika</th>\n",
       "      <th>zumwalt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 1811 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     abcnews  able  abortion  abrams  absolutely  aca  access  accessibility  \\\n",
       "0          0     0         0       0           0    0       0              0   \n",
       "1          0     0         0       0           0    0       0              0   \n",
       "2          0     0         0       0           0    0       0              0   \n",
       "3          0     0         0       0           0    0       0              0   \n",
       "4          0     0         0       0           0    0       0              0   \n",
       "..       ...   ...       ...     ...         ...  ...     ...            ...   \n",
       "195        0     0         0       0           0    0       0              0   \n",
       "196        0     0         0       0           0    0       0              0   \n",
       "197        0     0         0       0           0    0       1              0   \n",
       "198        0     0         0       0           0    0       0              0   \n",
       "199        0     0         0       0           0    0       0              0   \n",
       "\n",
       "     accomplish  accordingly  ...  yesterday  yet  yorkers  young  youth  \\\n",
       "0             0            0  ...          0    0        0      0      0   \n",
       "1             0            0  ...          0    0        0      0      0   \n",
       "2             0            0  ...          0    0        0      0      0   \n",
       "3             0            0  ...          0    0        0      0      0   \n",
       "4             0            0  ...          0    0        0      0      0   \n",
       "..          ...          ...  ...        ...  ...      ...    ...    ...   \n",
       "195           0            0  ...          0    0        0      0      0   \n",
       "196           0            0  ...          0    0        0      0      0   \n",
       "197           0            0  ...          0    0        0      0      0   \n",
       "198           0            0  ...          0    0        0      0      0   \n",
       "199           0            0  ...          0    0        0      0      0   \n",
       "\n",
       "     youtube  yr  zero  zika  zumwalt  \n",
       "0          0   0     0     0        0  \n",
       "1          0   0     0     0        0  \n",
       "2          0   0     0     0        4  \n",
       "3          0   0     0     0        0  \n",
       "4          0   0     0     0        0  \n",
       "..       ...  ..   ...   ...      ...  \n",
       "195        0   0     0     0        0  \n",
       "196        0   0     0     0        0  \n",
       "197        0   0     0     0        0  \n",
       "198        0   0     0     0        0  \n",
       "199        0   0     0     0        0  \n",
       "\n",
       "[200 rows x 1811 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 4],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, include these vectors as a new column named bow_vector in your datasets \n",
    "\n",
    "data_train['bow_vector']=text_bow[0:len(data_train)].toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party_id</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>bow_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>KUSI</td>\n",
       "      <td>10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "      <td>rt  kusinews  one longtime viewer congressma...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>111</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>R</td>\n",
       "      <td>today  urge  cdcgov immediately launch  phon...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>MO03</td>\n",
       "      <td>2</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>R</td>\n",
       "      <td>tomorrow   mo senior graduate calvary lutheran...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>TeamUSA WorldJuniors</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "      <td>congrats  teamusa canton native  jgreenway win...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>ImmigrantHeritageMonth</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "      <td>pleased support  amergateways june fiesta  hon...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>35</td>\n",
       "      <td>b'In 5 years of DACA, over 780,000 #DREAMers h...</td>\n",
       "      <td>DREAMers SaveDACA</td>\n",
       "      <td>17</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "      <td>in  year daca    dreamers give chance work stu...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>118</td>\n",
       "      <td>b'Over 90% of gun owners support expanding bac...</td>\n",
       "      <td>OutShoutTheGunLobby</td>\n",
       "      <td>39</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "      <td>over   gun owner support expand background che...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>26</td>\n",
       "      <td>b'Holi is a time to celebrate renewal &amp;amp; a ...</td>\n",
       "      <td>Holi2015</td>\n",
       "      <td>21</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>D</td>\n",
       "      <td>holi time celebrate renewal  amp  strengthenin...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>78</td>\n",
       "      <td>b'Connecticut\\xe2\\x80\\x99s 4th District lost t...</td>\n",
       "      <td>911remembrance</td>\n",
       "      <td>6</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "      <td>connecticutxexs th district lose many mom  dad...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6</td>\n",
       "      <td>b'Always great catching up with @GlennVaagen @...</td>\n",
       "      <td>FarmBill WA04</td>\n",
       "      <td>2</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>R</td>\n",
       "      <td>always great catch  glennvaagen  waagnetwork u...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    favorite_count                                          full_text  \\\n",
       "0                0  b\"RT @KUSINews: One of our longtime viewers wa...   \n",
       "1              258  b\"Today I'm urging the @CDCgov to immediately ...   \n",
       "2                0  b'Tomorrow, #MO03 seniors graduate from Calvar...   \n",
       "3                9  b'Congrats to #TeamUSA and Canton Native @JGre...   \n",
       "4                3  b'Pleased to support @amergateways at their Ju...   \n",
       "..             ...                                                ...   \n",
       "95              35  b'In 5 years of DACA, over 780,000 #DREAMers h...   \n",
       "96             118  b'Over 90% of gun owners support expanding bac...   \n",
       "97              26  b'Holi is a time to celebrate renewal &amp; a ...   \n",
       "98              78  b'Connecticut\\xe2\\x80\\x99s 4th District lost t...   \n",
       "99               6  b'Always great catching up with @GlennVaagen @...   \n",
       "\n",
       "                  hashtags  retweet_count    year party_id  \\\n",
       "0                     KUSI             10  2017.0        R   \n",
       "1              Coronavirus            111  2020.0        R   \n",
       "2                     MO03              2  2014.0        R   \n",
       "3     TeamUSA WorldJuniors              3  2017.0        R   \n",
       "4   ImmigrantHeritageMonth              3  2019.0        D   \n",
       "..                     ...            ...     ...      ...   \n",
       "95       DREAMers SaveDACA             17  2017.0        D   \n",
       "96     OutShoutTheGunLobby             39  2017.0        D   \n",
       "97                Holi2015             21  2015.0        D   \n",
       "98          911remembrance              6  2018.0        D   \n",
       "99           FarmBill WA04              2  2018.0        R   \n",
       "\n",
       "                                           text_clean  \\\n",
       "0     rt  kusinews  one longtime viewer congressma...   \n",
       "1     today  urge  cdcgov immediately launch  phon...   \n",
       "2   tomorrow   mo senior graduate calvary lutheran...   \n",
       "3   congrats  teamusa canton native  jgreenway win...   \n",
       "4   pleased support  amergateways june fiesta  hon...   \n",
       "..                                                ...   \n",
       "95  in  year daca    dreamers give chance work stu...   \n",
       "96  over   gun owner support expand background che...   \n",
       "97  holi time celebrate renewal  amp  strengthenin...   \n",
       "98  connecticutxexs th district lose many mom  dad...   \n",
       "99  always great catch  glennvaagen  waagnetwork u...   \n",
       "\n",
       "                                           bow_vector  \n",
       "0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "..                                                ...  \n",
       "95  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "96  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "97  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "98  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "99  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, include these vectors as a new column named bow_vector in your datasets \n",
    "\n",
    "data_test['bow_vector']=text_bow[len(data_train):len(data)].toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>bow_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>b'#TaxReform improved the playing field for Am...</td>\n",
       "      <td>TaxReform</td>\n",
       "      <td>13</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "      <td>taxreform improve playing field american wo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>b'This #NativeWomensEqualPay Day, we recommit ...</td>\n",
       "      <td>NativeWomensEqualPay</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>this  nativewomensequalpay day  recommit pass ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>b\"\\xe2\\x80\\x9cI became convinced that our gene...</td>\n",
       "      <td>MeToo ShatteringTheSilence</td>\n",
       "      <td>24</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "      <td>xexci become convinced generation silence ma...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>b'During #NationalAdoptionMonth, we honor the ...</td>\n",
       "      <td>NationalAdoptionMonth</td>\n",
       "      <td>2</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "      <td>during  nationaladoptionmonth  honor adoptive ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>b'Happy #AirborneDay to our @USArmy paratroope...</td>\n",
       "      <td>AirborneDay AirborneAllTheWay</td>\n",
       "      <td>7</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "      <td>happy  airborneday  usarmy paratrooper veteran...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>66</td>\n",
       "      <td>b\"I've never been more confused in my life. An...</td>\n",
       "      <td>whiteandgold blackandblue</td>\n",
       "      <td>78</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>D</td>\n",
       "      <td>ve never confused life  ve listen  replouieg...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>678</td>\n",
       "      <td>b'This is progress #coronarvirus https://t.co/...</td>\n",
       "      <td>coronarvirus</td>\n",
       "      <td>224</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>D</td>\n",
       "      <td>this progress  coronarvirus http  cohsplcjy</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>b'.@HouseGOP voted to reduce child care access...</td>\n",
       "      <td>WEmatter</td>\n",
       "      <td>11</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>D</td>\n",
       "      <td>housegop vote reduce child care access  de...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Our Army is equally ready to assist in a dis...</td>\n",
       "      <td>MilitaryMonday</td>\n",
       "      <td>0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>D</td>\n",
       "      <td>our army equally ready assist disaster  amp  e...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>28</td>\n",
       "      <td>b'There is no racial justice without environme...</td>\n",
       "      <td>COVID19</td>\n",
       "      <td>14</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>D</td>\n",
       "      <td>there racial justice without environmental  am...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  favorite_count                                          full_text  \\\n",
       "0    0              70  b'#TaxReform improved the playing field for Am...   \n",
       "1    1              27  b'This #NativeWomensEqualPay Day, we recommit ...   \n",
       "2    2              49  b\"\\xe2\\x80\\x9cI became convinced that our gene...   \n",
       "3    3              14  b'During #NationalAdoptionMonth, we honor the ...   \n",
       "4    4              13  b'Happy #AirborneDay to our @USArmy paratroope...   \n",
       "..  ..             ...                                                ...   \n",
       "95  95              66  b\"I've never been more confused in my life. An...   \n",
       "96  96             678  b'This is progress #coronarvirus https://t.co/...   \n",
       "97  97               5  b'.@HouseGOP voted to reduce child care access...   \n",
       "98  98               0  b'Our Army is equally ready to assist in a dis...   \n",
       "99  99              28  b'There is no racial justice without environme...   \n",
       "\n",
       "                         hashtags  retweet_count    year party  \\\n",
       "0                       TaxReform             13  2018.0     D   \n",
       "1            NativeWomensEqualPay             11     NaN     D   \n",
       "2      MeToo ShatteringTheSilence             24  2017.0     D   \n",
       "3           NationalAdoptionMonth              2  2019.0     D   \n",
       "4   AirborneDay AirborneAllTheWay              7  2018.0     D   \n",
       "..                            ...            ...     ...   ...   \n",
       "95      whiteandgold blackandblue             78  2015.0     D   \n",
       "96                   coronarvirus            224  2020.0     D   \n",
       "97                       WEmatter             11  2014.0     D   \n",
       "98                 MilitaryMonday              0  2016.0     D   \n",
       "99                        COVID19             14  2020.0     D   \n",
       "\n",
       "                                           text_clean  \\\n",
       "0      taxreform improve playing field american wo...   \n",
       "1   this  nativewomensequalpay day  recommit pass ...   \n",
       "2     xexci become convinced generation silence ma...   \n",
       "3   during  nationaladoptionmonth  honor adoptive ...   \n",
       "4   happy  airborneday  usarmy paratrooper veteran...   \n",
       "..                                                ...   \n",
       "95    ve never confused life  ve listen  replouieg...   \n",
       "96       this progress  coronarvirus http  cohsplcjy    \n",
       "97      housegop vote reduce child care access  de...   \n",
       "98  our army equally ready assist disaster  amp  e...   \n",
       "99  there racial justice without environmental  am...   \n",
       "\n",
       "                                           bow_vector  \n",
       "0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "2   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "..                                                ...  \n",
       "95  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "96  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "97  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "98  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "99  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Word2vec\n",
    "\n",
    "# Following from [2]\n",
    "\n",
    "model = gensim.models.Word2Vec(data, min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7fc118640e20>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **References**\n",
    "\n",
    "[1] https://www.analyticsvidhya.com/blog/2021/08/a-friendly-guide-to-nlp-bag-of-words-with-python-example/\n",
    "\n",
    "[2] https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
