{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4060cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk #language processing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882edc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"congressional_tweet_training_data.csv\",names=None)\n",
    "data_test= pd.read_csv(\"congressional_tweet_test_data.csv\",names=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['party_class']=data_train['party_id'].apply(lambda x: 0 if x=='D' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5efaa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['party_class']=data_test['party'].apply(lambda x: 0 if x=='D' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6446cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "tokens_list=[word_tokenize(sent) for sent in data_train['full_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ceb057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pos Tag \n",
    "tagged_tokens =[pos_tag(sent) for sent in tokens_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6d4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag): #Following from [16]\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None # for easy if-statement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce8fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fbb232",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame(data_train['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65125cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['tagged_tokens']=tagged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11613e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_list = x['tagged_tokens'].transform(lambda value: ' '.join([lemmatizer.lemmatize(a[0],pos=get_wordnet_pos(a[1])) if get_wordnet_pos(a[1]) else a[0] for a in  value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['lemma_list']=lemma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b093b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e827786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers, words <2 characters, punctuation, links and emojis \n",
    "\n",
    "def emoji_free_text(text): # From [9] \n",
    "    return emoji.get_emoji_regexp().sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04fe151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        lower_token = token.lower()\n",
    "        len_check = len(lower_token) >= 2\n",
    "        #start_check = not (lower_token.startswith('http') or lower_token.startswith('\\\\') or lower_token.startswith(':'))\n",
    "        stop_word_check = lower_token not in stop_words\n",
    "        if len_check and stop_word_check:\n",
    "            lower_token=re.sub(r'\\d+', '', lower_token) \n",
    "            lower_token=re.sub(r'\\b\\w{1}\\b', '',  lower_token)  \n",
    "            lower_token=re.sub(r'[^\\w\\s]', '', lower_token)                 # Remove punctuation\n",
    "            lower_token=re.sub(r'http\\S+', '',lower_token)                 # Remove links\n",
    "            cleaned_tokens.append(re.sub('[,.!?]|<br \\/>\\+|<br \\/>', '', lower_token))\n",
    "    return ' '.join(cleaned_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca40f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_clean = x['lemma_list'].map(clean_text)\n",
    "Text_cleaner = Text_clean .map(emoji_free_text)\n",
    "data_train['text_clean']=Text_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514bc6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f82d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning test data set\n",
    "\n",
    "# test datasindaki naleri de silecek miyiz?\n",
    "\n",
    "# Tokenize\n",
    "tokens_list_test=[word_tokenize(sent) for sent in data_test['full_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d2979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pos Tag \n",
    "tagged_tokens_test =[pos_tag(sent) for sent in tokens_list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c427b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=pd.DataFrame(data_test['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26d72ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2['tagged_tokens_test']=tagged_tokens_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_list_test = x2['tagged_tokens_test'].transform(lambda value: ' '.join([lemmatizer.lemmatize(a[0],pos=get_wordnet_pos(a[1])) if get_wordnet_pos(a[1]) else a[0] for a in  value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edade8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2['lemma_list_test']=lemma_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68474fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_clean_test = x2['lemma_list_test'].map(clean_text)\n",
    "Text_cleaner_test = Text_clean_test .map(emoji_free_text)\n",
    "data_test['text_clean_test']=Text_cleaner_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1be1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9db8bc",
   "metadata": {},
   "source": [
    "#### Naive Bayes with Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ea070",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train['text_clean']\n",
    "y_train = data_train['party_class']\n",
    "\n",
    "X_test = data_test['text_clean_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74609910",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=data_train['text_clean'] \n",
    "text2=data_test['text_clean_test'] \n",
    "frames = [text, text2]\n",
    "  \n",
    "result = pd.concat(frames)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be87f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf=TfidfVectorizer()\n",
    "X=tfidf.fit_transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X[0:592803]\n",
    "y_train=data_train['party_class']\n",
    "X_test=X[592803:857803]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2afa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b3809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b467e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735b66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=pd.DataFrame(data=y_test, columns=['party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e9265",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['party']=y_test3['party'].apply(lambda x: 'D' if x==0 else 'R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba3e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ffc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv('ytest_nb_clean_text_istanbul.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
